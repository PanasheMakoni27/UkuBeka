<!DOCTYPE html>
<html lang="en" class="scroll-smooth antialiased bg-brand-dark text-brand-dark-text">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UkuBeka â€“ Gesture-to-Text Communication</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <!-- Tailwind CDN for development/prototyping -->
    <script src="https://cdn.tailwindcss.com?plugins=forms,typography,aspect-ratio"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            colors: {
              primary: '#1976d2',
              secondary: '#4fc3f7',
              accent: '#81c784',
              dark: '#181c24',
              light: '#f4f4f4',
              error: '#ff0033',
              success: '#00ff6a',
              warning: '#ffb300',
              info: '#4fc3f7',
              muted: '#b0bec5',
              'dark-text': '#f4f4f4',
              'light-text': '#23272f',
            },
            fontFamily: {
              brand: [
                'Segoe UI', 'Roboto', 'Open Sans', 'Arial', 'sans-serif'
              ]
            },
            borderRadius: {
              brand: '24px',
            },
            boxShadow: {
              brand: '0 4px 32px #1976d233, 0 1.5px 8px #23272f44',
            },
            backgroundImage: {
              'brand-gradient': 'linear-gradient(135deg, #1976d2 0%, #4fc3f7 100%)',
            },
          }
        }
      }
    </script>
</head>
<body class="font-brand min-h-screen bg-gradient-to-br from-brand-dark to-brand-secondary text-brand-dark-text transition-colors duration-500">
    <header class="flex items-center gap-4 py-4 px-4 md:px-6 rounded-brand shadow-brand bg-brand-gradient mb-8 w-full max-w-7xl mx-auto">
        <div class="flex-shrink-0 w-10 h-10 md:w-12 md:h-12 flex items-center justify-center rounded-full bg-white/80 shadow-md" aria-hidden="true">
            <!-- Modern SVG Logo Placeholder -->
            <svg class="logo-img" width="48" height="48" viewBox="0 0 48 48" fill="none" aria-label="UkuBeka Logo" role="img">
                <circle cx="24" cy="24" r="22" fill="url(#grad1)" stroke="#1976d2" stroke-width="2"/>
                <path d="M16 32 Q24 16 32 32" stroke="#fff" stroke-width="3" fill="none"/>
                <circle cx="24" cy="24" r="6" fill="#4fc3f7"/>
                <defs>
                    <linearGradient id="grad1" x1="0" y1="0" x2="48" y2="48" gradientUnits="userSpaceOnUse">
                        <stop stop-color="#1976d2"/>
                        <stop offset="1" stop-color="#4fc3f7"/>
                    </linearGradient>
                </defs>            </svg>
        </div>
        <div class="flex flex-col items-center w-full">
            <h1 class="text-2xl md:text-3xl font-bold text-white tracking-wide text-center">UkuBeka</h1>
            <div class="text-base md:text-lg font-medium text-light-text mt-1 text-center" tabindex="0">Bridge communication. Empower lives.</div>
        </div>
    </header>
    <!-- Apply light South African-inspired background for commercial appeal -->
    <div class="min-h-screen bg-[#fff8e1] text-[#333333] flex flex-col items-center py-12 px-4">
      <div class="container mx-auto px-2 sm:px-4 max-w-7xl flex flex-col gap-8">
          <button class="fixed top-4 right-4 z-50 w-10 h-10 rounded-full bg-light text-primary shadow-md flex items-center justify-center hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-primary transition-colors duration-200" id="themeToggle" title="Toggle light/dark mode" aria-label="Toggle light or dark mode"></button>
      </div>
      <main class="flex flex-col md:flex-row justify-center items-start gap-8 w-full max-w-[1200px] mx-auto mt-[-6rem] md:mt-[-8rem]" aria-label="Main content panels">
          <section class="bg-dark/80 rounded-brand shadow-brand p-4 md:p-6 flex flex-col items-center gap-4 w-full max-w-md ml-0 md:mx-0" aria-labelledby="gestureDetectionTitle" role="region" tabindex="0">
              <h2 id="gestureDetectionTitle" tabindex="-1" class="text-xl md:text-2xl font-bold text-light-text mb-2">Gesture Detection</h2>
              <div class="flex items-center justify-center w-12 h-12 md:w-16 md:h-16 rounded-full bg-secondary/20 shadow-inner mb-2 animate-pulse" aria-hidden="true">
                  <svg width="48" height="48" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false">
                      <rect x="6" y="14" width="36" height="24" rx="4" fill="#4fc3f7"/>
                      <rect x="14" y="8" width="20" height="8" rx="2" fill="#b3e5fc"/>
                      <circle cx="24" cy="26" r="7" fill="#181c24" stroke="#90caf9" stroke-width="2"/>
                      <circle cx="24" cy="26" r="3" fill="#90caf9"/>
                  </svg>
              </div>
              <span class="text-xs md:text-sm text-muted font-medium mt-2" id="cameraPreviewLabel">Camera Preview</span>
              <p class="text-xs text-muted mb-2" id="cameraInstruction">Start recording to begin gesture detection</p>
              <div class="relative aspect-video w-full max-w-xs rounded-lg overflow-hidden border-4 border-muted shadow-inner flex items-center justify-center bg-black" id="webcamArea" aria-label="Live camera feed with gesture overlay" role="group">
                  <video id="webcam" aria-label="Live camera view" aria-describedby="cameraPreviewLabel cameraInstruction" autoplay playsinline muted class="absolute top-0 left-0 w-full h-full object-cover z-10 rounded-lg" tabindex="0"></video>
                  <canvas id="overlay" aria-label="Gesture overlay" class="absolute top-0 left-0 w-full h-full z-20 pointer-events-none" tabindex="-1"></canvas>
                  <div class="absolute inset-0 flex items-center justify-center text-muted text-base md:text-lg font-semibold bg-black/70 z-30" id="webcamPlaceholder" aria-live="polite" aria-atomic="true">Camera unavailable</div>
              </div>
              <div id="results" class="mt-2"></div>
              <button class="mt-4 px-4 md:px-6 py-2 rounded-full bg-primary text-white font-semibold shadow-lg hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-accent active:scale-95 transition-all duration-200 w-full md:w-auto" id="startDetectionBtn" type="button" aria-pressed="false" aria-controls="webcamArea" aria-label="Start or stop gesture detection">
                  Start Detection
              </button>
          </section>
          <section class="bg-light rounded-brand shadow-brand p-4 md:p-6 flex flex-col gap-2 w-full max-w-xs ml-0 md:mx-0 text-black" aria-label="Session statistics" tabindex="0">
              <h3 class="text-base md:text-lg font-semibold text-primary mb-2">Session Statistics</h3>
              <div class="flex justify-between items-center py-1">
                  <div class="text-xs md:text-sm text-muted">Words</div>
                  <div class="text-sm md:text-base font-bold" id="statsWords">0</div>
              </div>
              <div class="flex justify-between items-center py-1">
                  <div class="text-xs md:text-sm text-muted">Accuracy</div>
                  <div class="text-sm md:text-base font-bold" id="statsAccuracy">0%</div>
              </div>
              <div class="flex justify-between items-center py-1">
                  <div class="text-xs md:text-sm text-muted">Status</div>
                  <div class="text-sm md:text-base font-bold" id="statsStatus">Idle</div>
              </div>
          </section>
          <section class="bg-light rounded-brand shadow-brand p-4 md:p-6 flex flex-col items-center gap-4 w-full max-w-md ml-0 md:mx-0 text-black" aria-label="Translated text panel" tabindex="0">
              <h2 class="text-xl md:text-2xl font-bold text-light-text mb-2">Translated Text</h2>
              <div class="hand-icon mb-2" aria-hidden="true">
                  <svg width="48" height="48" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
                      <path d="M14 28V14a4 4 0 1 1 8 0v14" stroke="#81c784" stroke-width="3" stroke-linecap="round"/>
                      <path d="M22 28V10a4 4 0 1 1 8 0v18" stroke="#81c784" stroke-width="3" stroke-linecap="round"/>
                      <path d="M30 28V18a4 4 0 1 1 8 0v10" stroke="#81c784" stroke-width="3" stroke-linecap="round"/>
                      <rect x="10" y="28" width="28" height="10" rx="5" fill="#c8e6c9"/>
                  </svg>
              </div>
              <div class="text-xs md:text-sm text-muted mb-2">Start gesture detection to see translated text here</div>
              <div id="translatedTextPanel" class="w-full">
                  <div id="translatedText" class="flex flex-col gap-2 min-h-[2.5rem] text-base md:text-lg font-medium text-dark-text bg-secondary/10 rounded-md px-4 py-2 mb-2 transition-colors duration-200" aria-live="polite" aria-atomic="true">
                      <!-- Translated text will appear here -->
                  </div>
                  <div class="flex flex-col gap-2">
                      <div class="flex justify-between items-center">
                          <span class="text-xs md:text-sm text-muted">Translation:</span>
                          <span class="text-sm md:text-base font-bold" id="translationWord">---</span>
                      </div>
                      <div class="flex justify-between items-center">
                          <span class="text-xs md:text-sm text-muted">Pronunciation:</span>
                          <span class="text-sm md:text-base font-bold" id="pronunciationWord">---</span>
                      </div>
                  </div>
              </div>
              <button class="mt-4 px-4 py-2 rounded-full bg-gray-300 text-gray-800 font-semibold shadow hover:bg-gray-400 focus:outline-none focus:ring-2 focus:ring-accent active:scale-95 transition-all duration-200 w-full md:w-auto" id="clearBtn">Clear</button>
          </section>
      </main>
    </div>
    <!-- Spinner and feedback animations -->
    <div class="spinner animate-spin w-8 h-8 border-4 border-secondary border-t-transparent rounded-full mx-auto my-4" id="spinner" style="display:none"></div>
    <div class="recognized-gesture animate-fade-in-up text-success font-bold text-lg mb-2" style="display:none"></div>
    <!-- MediaPipe Hands and Drawing Utils -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script>
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('overlay');
        const ctx = canvas.getContext('2d');
        const webcamArea = document.getElementById('webcamArea');
        const resultsArea = document.getElementById('results');
        const spinner = document.getElementById('spinner');
        const waitingText = document.getElementById('waitingText');
        const translationWord = document.getElementById('translationWord');
        const translatedText = document.getElementById('translatedText');
        let handDetected = false;
        let lastGesture = '';
        // Theme toggle
        const themeToggle = document.getElementById('themeToggle');
        themeToggle.onclick = () => {
            const isDark = document.body.getAttribute('data-theme') === 'dark';
            document.body.setAttribute('data-theme', isDark ? 'light' : 'dark');
            themeToggle.textContent = isDark ? 'ðŸŒ™' : 'â˜€ï¸';
        };
        // Set default theme
        if (!document.body.getAttribute('data-theme')) {
            document.body.setAttribute('data-theme', 'light');
        }
        // Resize canvas to match video
        function resizeCanvas() {
            if (video.videoWidth > 0 && video.videoHeight > 0) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }
        }
        // Access webcam
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false })
                .then(function(stream) {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        video.play();
                        resizeCanvas();
                    };
                })
                .catch(function(err) {
                    console.error('Webcam error:', err);
                    resultsArea.innerHTML = '<span style="color:red">Webcam access denied or not available.<br>' + err.message + '</span>';
                });
        } else {
            resultsArea.innerHTML = '<span style="color:red">Webcam not supported by this browser.</span>';
        }
        // Example gesture classifier (replace with your model or backend call)
        function classifyGesture(flatLandmarks) {
            // Simple ruleset for demonstration (replace with ML model or backend call)
            // Example: If the hand is open (distance between wrist and middle finger tip is large), return 'Hello'
            // If the hand is closed (distance is small), return 'Fist'
            // This is just a placeholder logic
            if (!flatLandmarks || flatLandmarks.length !== 42) return null;
            const wristX = flatLandmarks[0], wristY = flatLandmarks[1];
            const midTipX = flatLandmarks[16], midTipY = flatLandmarks[17]; // 8th landmark (index 8*2)
            const dx = midTipX - wristX;
            const dy = midTipY - wristY;
            const dist = Math.sqrt(dx*dx + dy*dy);
            if (dist > 0.2) return 'Hello';
            if (dist < 0.1) return 'Fist';
            return 'Unknown';
        }

        function preprocessLandmarks(landmarks) {
            // Normalize landmarks to wrist (landmark 0)
            if (!landmarks || landmarks.length !== 21) return null;
            const baseX = landmarks[0].x, baseY = landmarks[0].y;
            let flat = [];
            for (let i = 0; i < 21; i++) {
                flat.push(landmarks[i].x - baseX);
                flat.push(landmarks[i].y - baseY);
            }
            return flat;
        }

        function drawConfidenceMeter(confidence, x, y) {
            // Draw a circular confidence meter at (x, y)
            const radius = 28;
            ctx.save();
            ctx.beginPath();
            ctx.arc(x, y, radius, 0, 2 * Math.PI);
            ctx.strokeStyle = '#4fc3f7';
            ctx.lineWidth = 4;
            ctx.globalAlpha = 0.7;
            ctx.stroke();
            ctx.beginPath();
            ctx.arc(x, y, radius, -Math.PI/2, (2 * Math.PI * confidence) - Math.PI/2);
            ctx.strokeStyle = confidence > 0.7 ? '#81c784' : (confidence > 0.4 ? '#ffb300' : '#ff0033');
            ctx.lineWidth = 6;
            ctx.globalAlpha = 1.0;
            ctx.stroke();
            ctx.restore();
        }
        function drawGestureTrail(trail) {
            if (!trail || trail.length < 2) return;
            ctx.save();
            ctx.strokeStyle = '#1976d2';
            ctx.lineWidth = 3;
            ctx.globalAlpha = 0.5;
            ctx.beginPath();
            ctx.moveTo(trail[0].x, trail[0].y);
            for (let i = 1; i < trail.length; i++) {
                ctx.lineTo(trail[i].x, trail[i].y);
            }
            ctx.stroke();
            ctx.restore();
        }
        let gestureTrail = [];
        let lastTrailTime = 0;
        let possibleMatches = [];
        let lastPrediction = null;
        let lastConfidence = 0;
        function onResults(results) {
            ctx.save();
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.globalAlpha = 1.0;
            let landmarkData = [];
            handDetected = false;
            let gestureText = 'Waiting for gestureâ€¦';
            possibleMatches = [];
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                handDetected = true;
                for (const landmarks of results.multiHandLandmarks) {
                    window.drawConnectors(ctx, landmarks, window.HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 2});
                    window.drawLandmarks(ctx, landmarks, {color: '#FF0000', lineWidth: 1});
                    landmarkData.push(landmarks.map(lm => ({x: lm.x, y: lm.y, z: lm.z})));
                    // Gesture trail (use index finger tip)
                    const tip = landmarks[8];
                    if (tip) {
                        const px = tip.x * canvas.width;
                        const py = tip.y * canvas.height;
                        if (Date.now() - lastTrailTime > 20) {
                            gestureTrail.push({x: px, y: py});
                            if (gestureTrail.length > 40) gestureTrail.shift();
                            lastTrailTime = Date.now();
                        }
                    }
                    drawGestureTrail(gestureTrail);
                }
            } else {
                gestureTrail = [];
            }
            ctx.restore();
            // Glowing border
            if (webcamArea) {
                webcamArea.classList.toggle('glow-green', handDetected);
                webcamArea.classList.toggle('glow-red', !handDetected);
            }
            // Show spinner/pulse if no gesture
            if (!handDetected) {
                if (spinner) spinner.style.display = '';
                if (waitingText) waitingText.style.display = '';
                if (resultsArea) resultsArea.querySelectorAll('.recognized-gesture').forEach(e => e.remove());
                lastGesture = '';
                if (translationWord) translationWord.textContent = '---';
                if (translatedText) translatedText.textContent = 'Waiting for gestureâ€¦';
                return;
            }
            // Send to backend if any hand detected
            if (landmarkData.length > 0) {
                fetch('/predict', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({hands: landmarkData})
                })
                .then(res => res.json())
                .then(data => {
                    if (spinner) spinner.style.display = 'none';
                    if (waitingText) waitingText.style.display = 'none';
                    if (data.prediction && data.prediction !== lastGesture) {
                        lastGesture = data.prediction;
                        if (resultsArea) resultsArea.querySelectorAll('.recognized-gesture').forEach(e => e.remove());
                        // Slide-in animated feedback
                        if (resultsArea) {
                            const gestureDiv = document.createElement('div');
                            gestureDiv.className = 'recognized-gesture animate-fade-in-up';
                            gestureDiv.textContent = `Gesture recognized: ${data.prediction}`;
                            resultsArea.appendChild(gestureDiv);
                        }
                        if (translationWord) translationWord.textContent = data.prediction;
                        if (translatedText) translatedText.textContent = data.prediction;
                        // Voice output
                        if ('speechSynthesis' in window) {
                            const utter = new SpeechSynthesisUtterance(data.prediction);
                            utter.lang = 'en-ZA';
                            window.speechSynthesis.cancel();
                            window.speechSynthesis.speak(utter);
                        }
                    }
                    // Confidence meter and possible matches
                    if (data.confidence !== undefined) {
                        lastConfidence = data.confidence;
                        // Draw confidence meter at top right
                        drawConfidenceMeter(lastConfidence, canvas.width - 50, 50);
                    }
                    if (data.possible_matches) {
                        possibleMatches = data.possible_matches;
                        // Show suggestions below translation
                        let suggestionHtml = possibleMatches.map(m => `<span class='suggestion'>${m}</span>`).join(' ');
                        if (translatedText) translatedText.innerHTML = data.prediction + '<br><span class="suggestions">' + suggestionHtml + '</span>';
                    }
                })
                .catch(() => {
                    if (spinner) spinner.style.display = 'none';
                    if (waitingText) waitingText.style.display = 'none';
                    if (resultsArea) resultsArea.innerHTML = '<span style="color:red">Error sending data.</span>';
                    if (translationWord) translationWord.textContent = '---';
                    if (translatedText) translatedText.textContent = 'Waiting for gestureâ€¦';
                });
            }
        }
        let hands;
        function setupHands() {
            hands = new window.Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            hands.setOptions({
                maxNumHands: 2,
                modelComplexity: 1,
                minDetectionConfidence: 0.7,
                minTrackingConfidence: 0.7
            });
            hands.onResults(onResults);
        }
        // Start Detection button logic
        const startDetectionBtn = document.getElementById('startDetectionBtn');
        let detectionActive = false;
        let animationFrameId = null;

        function startHandTracking() {
            if (!hands) return;
            detectionActive = true;
            async function processFrame() {
                if (!detectionActive) return;
                if (video.readyState === 4 && video.videoWidth > 0 && video.videoHeight > 0) {
                    resizeCanvas();
                    await hands.send({image: video});
                }
                animationFrameId = requestAnimationFrame(processFrame);
            }
            processFrame();
        }

        function stopHandTracking() {
            detectionActive = false;
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            if (webcamArea) webcamArea.classList.remove('glow-green', 'glow-red');
            if (translationWord) translationWord.textContent = '---';
            if (translatedText) translatedText.textContent = 'Waiting for gestureâ€¦';
        }

        startDetectionBtn.addEventListener('click', () => {
            if (!detectionActive) {
                startDetectionBtn.textContent = 'Stop Detection';
                startHandTracking();
            } else {
                startDetectionBtn.textContent = 'Start Detection';
                stopHandTracking();
            }
        });

        window.addEventListener('DOMContentLoaded', () => {
            setupHands();
            // Do not auto-start detection
            startDetectionBtn.textContent = 'Start Detection';
        });
        // --- Gesture Edit Modal ---
        function showGestureEdit(prediction, possibleMatches) {
            // Simple modal for editing/correcting gesture before confirmation
            let modal = document.createElement('div');
            modal.className = 'gesture-edit-modal';
            modal.innerHTML = `
                <div class='modal-content'>
                    <h3>Edit or Confirm Gesture</h3>
                    <div>Prediction: <b>${prediction || ''}</b></div>
                    <div>Suggestions: ${possibleMatches.map(m => `<button class='suggestion-btn'>${m}</button>`).join(' ')}</div>
                    <input type='text' id='gestureEditInput' value='${prediction || ''}' style='margin-top:1rem;width:90%;font-size:1.1rem;padding:0.5rem;border-radius:8px;border:1px solid #ccc;'>
                    <div style='margin-top:1.2rem;'>
                        <button id='confirmGestureBtn' class='start-detection-btn'>Confirm</button>
                        <button id='cancelGestureBtn' class='clear-btn'>Cancel</button>
                    </div>
                </div>
            `;
            document.body.appendChild(modal);
            document.getElementById('confirmGestureBtn').onclick = () => {
                let val = document.getElementById('gestureEditInput').value;
                if (translationWord) translationWord.textContent = val;
                if (translatedText) translatedText.textContent = val;
                document.body.removeChild(modal);
            };
            document.getElementById('cancelGestureBtn').onclick = () => {
                document.body.removeChild(modal);
            };
            modal.querySelectorAll('.suggestion-btn').forEach(btn => {
                btn.onclick = () => {
                    document.getElementById('gestureEditInput').value = btn.textContent;
                };
            });
        }
        // Add edit button to translation output
        if (translationWord) {
            translationWord.insertAdjacentHTML('afterend', `<button id='editGestureBtn' class='clear-btn' style='margin-left:1rem;margin-top:0.2rem;font-size:0.9rem;padding:0.3rem 1.2rem;'>Edit</button>`);
            document.getElementById('editGestureBtn').onclick = () => {
                showGestureEdit(translationWord.textContent, possibleMatches);
            };
        }
    </script>
</body>
</html>
